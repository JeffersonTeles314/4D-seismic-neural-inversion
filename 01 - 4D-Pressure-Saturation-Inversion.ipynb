{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D Neural Network Inversion Training\n",
    "This notebook generates a model for the notebook in [`02 - 4D-Inversion-Field-Data`](02 - 4D-Inversion-Field-Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "The data was provided in Matlab data format.\n",
    "It is available as Pressure, Gas Saturation and Water Saturation maps together and to increase training data, also available as isolated effects. Additionally, pore volume maps turned out to be essential for a successful inversion.\n",
    "\n",
    "Each map contains values for $\\Delta P$, $\\Delta S_g$, $\\Delta S_w$ maps and simulated seismic difference maps for near, mid and far in the `dSNA_syn_` words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_train_full():\n",
    "    seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    location = \"data\"\n",
    "    filename = \"Seis2PS_NN_training_input\"\n",
    "    suffixes = [\"\", \"_Ponly\", \"_SGonly\", \"_SWonly\"]\n",
    "    #suffixes = [\"\"]\n",
    "    out = pd.DataFrame()\n",
    "    for suff in suffixes:\n",
    "        seis_ps = loadmat(os.path.join(location,filename+suff))\n",
    "        headers = [\"dP\", \"dSg\", \"dSw\", \"dSNA_syn_nr\", \"dSNA_syn_md\", \"dSNA_syn_fr\"]\n",
    "        print(suff)\n",
    "        for q in range(len(seis_ps[\"dSg\"][0])):\n",
    "            tost = pd.DataFrame()\n",
    "            for x in headers:\n",
    "                tost[x] = seis_ps[x][0][q].ravel()\n",
    "            if suff == \"\":\n",
    "                pore = \"Pore_volume\"\n",
    "                pore_data = seis_ps[pore].ravel()\n",
    "                tost[pore] = pore_data\n",
    "            else:\n",
    "                tost[pore] = pore_data\n",
    "            out = out.append(tost)\n",
    "    out = out.dropna()\n",
    "    out = out.loc[~(out[[\"dP\", \"dSg\", \"dSw\"]]==0).all(axis=1)]\n",
    "    out = out.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    y_train = out[[\"dP\", \"dSg\", \"dSw\"]]\n",
    "    X_train = out[[\"dSNA_syn_nr\", \"dSNA_syn_md\", \"dSNA_syn_fr\", \"Pore_volume\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_test(q):\n",
    "    seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    location = \"data\"\n",
    "    filename = \"Seis2PS_NN_training_input\"\n",
    "    seis_ps = loadmat(os.path.join(location,filename))\n",
    "    headers = [\"dP\", \"dSg\", \"dSw\", \"dSNA_syn_nr\", \"dSNA_syn_md\", \"dSNA_syn_fr\"]\n",
    "    tost = pd.DataFrame()\n",
    "    for x in headers:\n",
    "        tost[x] = seis_ps[x][0][q].ravel()\n",
    "    \n",
    "    pore = \"Pore_volume\"\n",
    "    pore_data = seis_ps[pore].ravel()\n",
    "    tost[pore] = pore_data\n",
    "    \n",
    "    out = tost.dropna()\n",
    "    out = out.loc[~(out[[\"dP\", \"dSg\", \"dSw\"]]==0).all(axis=1)]\n",
    "\n",
    "    y_train = out[[\"dP\", \"dSg\", \"dSw\"]]\n",
    "    X_train = out[[\"dSNA_syn_nr\", \"dSNA_syn_md\", \"dSNA_syn_fr\", \"Pore_volume\"]]\n",
    "    \n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "The initial architecture was generated from an encoder decoder architecture using `hyperas` to optimize width, depth and dropout rate for predicting one synthetic map from the other time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, AlphaDropout, Dropout, Lambda, GaussianNoise, BatchNormalization, Concatenate\n",
    "from keras import regularizers\n",
    "from keras import optimizers \n",
    "from keras import callbacks\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback \n",
    "\n",
    "#from hyperopt import Trials, STATUS_OK, tpe\n",
    "#from hyperas import optim\n",
    "#from hyperas.distributions import choice, quniform, uniform, loguniform\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def r_square_loss(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def huber_loss(y_true, y_pred, clip_delta=.35):\n",
    "    error = y_true - y_pred\n",
    "    cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "    \n",
    "    return tf.where(cond, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_vae(near_off mid_off, far_off, noise=0.01, lr=1e-4):   \n",
    "    seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    alpha_dropout = 0.20\n",
    "    encoding_dims = 256\n",
    "    growth_factor = 1\n",
    "    \n",
    "    layers = 4\n",
    "    \n",
    "    \n",
    "    mid_near_offset = mid-near\n",
    "    far_near_offset = far-near\n",
    "    far_mid_offset  = far-mid\n",
    "    \n",
    "    near = Input(shape=(1,), name=\"near_input\")\n",
    "    mid = Input(shape=(1,), name=\"mid_input\")\n",
    "    far = Input(shape=(1,), name=\"far_input\")\n",
    "    pore = Input(shape=(1,), name=\"pore_input\")\n",
    "    noisy_near = GaussianNoise(noise)(near)\n",
    "    noisy_mid = GaussianNoise(noise)(mid)\n",
    "    noisy_far = GaussianNoise(noise)(far)\n",
    "    mid_near = Lambda(lambda inputs: ( inputs[0] - inputs[1] ) / ( mid_near_offset ))([noisy_mid, noisy_near])\n",
    "    far_near = Lambda(lambda inputs: ( inputs[0] - inputs[1] ) / ( far_near_offset ))([noisy_far, noisy_near])\n",
    "    far_mid = Lambda(lambda inputs: ( inputs[0] - inputs[1] ) / ( far_mid_offset ) )([noisy_far, noisy_mid])\n",
    "    \n",
    "    input_gradient = Concatenate()([noisy_near, noisy_mid, noisy_far, mid_near, far_near, far_mid, pore])\n",
    "    \n",
    "    encoded = Dense(encoding_dims*growth_factor*layers, activation=\"relu\", name=\"encoder_0\")(input_gradient)\n",
    "    encoded = Dropout(alpha_dropout)(encoded)\n",
    "    #encoded = BatchNormalization()(encoded)\n",
    "    \n",
    "    for q in range(layers):\n",
    "        encoded = Dense(encoding_dims*growth_factor*(layers-q), activation=\"relu\", name=\"encoder_\"+str(q+1))(encoded)\n",
    "        encoded = Dropout(alpha_dropout)(encoded)\n",
    "        #encoded = BatchNormalization()(encoded)\n",
    "    \n",
    "    z_mean = Dense(encoding_dims, name='z_mean')(encoded)\n",
    "    z_log_var = Dense(encoding_dims, name='z_log_var')(encoded)\n",
    "    \n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    deep_down = Lambda(sampling, name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    decoded0 = Dense(encoding_dims*growth_factor, activation=\"relu\", name=\"decoder_0\")(deep_down)\n",
    "                        \n",
    "    for q in range(2,layers):\n",
    "        #decoded0 = BatchNormalization()(decoded0)\n",
    "        decoded0 = Dropout(alpha_dropout)(decoded0)\n",
    "        decoded0 = Dense(encoding_dims*growth_factor*q, activation=\"relu\", name=\"decoder_\"+str(q-1))(decoded0)\n",
    "    \n",
    "    output0 = Dense(encoding_dims*growth_factor*layers, activation=\"linear\")(decoded0)\n",
    "    dP = Dense(1, activation=\"linear\", name=\"dP\")(output0)\n",
    "    output1 = Dense(encoding_dims*growth_factor*layers, activation=\"linear\")(decoded0)\n",
    "    dSw = Dense(1, activation=\"linear\", name=\"dSw\")(output1)\n",
    "    output2 = Dense(encoding_dims*growth_factor*layers, activation=\"linear\")(decoded0)\n",
    "    dSg = Dense(1, activation=\"linear\", name=\"dSg\")(output2)\n",
    "    \n",
    "    model = Model(inputs=[near, mid, far, pore], output=[dP,dSw,dSg])\n",
    "        \n",
    "    model.compile(loss=\"mse\", optimizer=optimizers.Nadam(lr=lr), metrics=[r_square])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_gen_train_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model  = build_vae(10,20,30,noise=0.00,lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop0 = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,mode='auto', restore_best_weights=True)\n",
    "earlystop1 = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=11,verbose=1,mode='auto', restore_best_weights=True)\n",
    "earlystop2 = callbacks.EarlyStopping(monitor='val_loss',min_delta=0,patience=51,verbose=1,mode='auto', restore_best_weights=False)\n",
    "ir1 = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose = 1, min_lr=0)\n",
    "ir2 = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=15, cooldown=10, verbose = 1, min_lr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training without Noise\n",
    "Clearly the network should converge on the model data. This "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(\n",
    "    [X_train[\"dSNA_syn_nr\"],X_train[\"dSNA_syn_md\"],X_train[\"dSNA_syn_fr\"],X_train[\"Pore_volume\"]],\n",
    "    [y_train[\"dP\"],y_train[\"dSw\"],y_train[\"dSg\"]],\n",
    "    batch_size= 400,\n",
    "    epochs=2000,\n",
    "    verbose=0,\n",
    "    shuffle=True,\n",
    "    validation_split=0.01,\n",
    "    callbacks = [TQDMNotebookCallback(leave_inner=True,leave_outer=True),earlystop1,ir1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pre.hd5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning On Noisy Data\n",
    "The final model has to expect noisy data to be able to transfer it to field data, we therefore rebuild the model and load the weights from the pre-trained network. This model will not converge particularly nor will it perform well on the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model  = build_vae(noise=0.02,lr=1e-4)\n",
    "model.load_weights(\"pre.hd5\")\n",
    "model.compile(loss=\"mse\", optimizer=optimizers.Nadam(lr=1e-4), metrics=[r_square])\n",
    "result = model.fit(\n",
    "    [X_train[\"dSNA_syn_nr\"],X_train[\"dSNA_syn_md\"],X_train[\"dSNA_syn_fr\"],X_train[\"Pore_volume\"]],\n",
    "    [y_train[\"dP\"],y_train[\"dSw\"],y_train[\"dSg\"]],\n",
    "    batch_size= 500,\n",
    "    epochs=2000,\n",
    "    verbose=0,\n",
    "    shuffle=True,\n",
    "    validation_split=0.01,\n",
    "    callbacks = [TQDMNotebookCallback(leave_inner=True,leave_outer=True),earlystop2,ir2],\n",
    ")\n",
    "model.save(\"bbest.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"publication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best.hd5\", custom_objects={'r_square': r_square, 'huber_loss': huber_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Generate the test data and evaluate the model on this data. You may notice that the \"test\" data is contained within the train data, which would be relevant, if the actual evaluation was done on the synthetic data. During the build phase, this map would be excluded from the train data to get valid results. (This is important.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data_gen_test(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evalutation on unseen data:\")\n",
    "print(model.evaluate([X_test[\"dSNA_syn_nr\"],X_test[\"dSNA_syn_md\"],X_test[\"dSNA_syn_fr\"],X_test[\"Pore_volume\"]], [y_test[\"dP\"],y_test[\"dSw\"],y_test[\"dSg\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "preddata  = model.predict([X_test[\"dSNA_syn_nr\"],X_test[\"dSNA_syn_md\"],X_test[\"dSNA_syn_fr\"],X_test[\"Pore_volume\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "The plotting rearranges the sample-wise prediction into the original map shape and deletes predictions, where data is not available.\n",
    "\n",
    "`model_shape` saves a mask of the data, we apply this map to the predictions to get rid of predictions on samples that did not contain _actual_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "location = \"data\"\n",
    "filename = \"Seis2PS_NN_training_input\"\n",
    "q=3\n",
    "pore_volume = loadmat(os.path.join(location,filename))[\"Pore_volume\"]\n",
    "seis_ps = loadmat(os.path.join(location,filename))\n",
    "ravel_data = seis_ps[\"dSNA_syn_nr\"][0][q].ravel()\n",
    "model_shape = ~np.isnan(ravel_data)\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "vmax=np.max(np.abs(seis_ps[\"dSNA_syn_nr\"][0][q]))\n",
    "plt.imshow(seis_ps[\"dSNA_syn_nr\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax,  aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title(\"Near\")\n",
    "plt.subplot(2, 2, 2)\n",
    "vmax=np.max(np.abs(seis_ps[\"dSNA_syn_md\"][0][q]))\n",
    "plt.imshow(seis_ps[\"dSNA_syn_md\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax,  aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title(\"Mid\")\n",
    "plt.subplot(2, 2, 3)\n",
    "vmax=np.max(np.abs(seis_ps[\"dSNA_syn_fr\"][0][q]))\n",
    "plt.imshow(seis_ps[\"dSNA_syn_fr\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax,  aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title(\"Far\")\n",
    "plt.subplot(2, 2, 4)\n",
    "vmax=np.nanmax(seis_ps[\"Pore_volume\"])\n",
    "plt.imshow(seis_ps[\"Pore_volume\"], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax,  aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title(\"Pore Volume\")\n",
    "plt.savefig(\"Seismic-input.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.full_like(seis_ps[\"dSg\"][0][0], np.nan)\n",
    "counter = 0\n",
    "for i, m in enumerate(model_shape):\n",
    "    if m:\n",
    "        data[np.unravel_index(i, data.shape)] = preddata[0][counter]\n",
    "        counter += 1\n",
    "vmax = np.nanmax([np.abs(data),np.abs(seis_ps[\"dP\"][0][q])])\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "\n",
    "im = axes[0].imshow(data, cmap=\"seismic\", vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[0].set_title(\"Neural Network dP \"+experiment)\n",
    "\n",
    "im = axes[1].imshow(seis_ps[\"dP\"][0][q], cmap=\"seismic\", vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[1].set_title(\"Test Data dP\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.2, 0.01, 0.6])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "blerg = \"dP\"\n",
    "mat_dict = {blerg+\"_nn_data\": data, blerg: seis_ps[blerg][0][q]}\n",
    "savemat('matlab/'+blerg+'.mat', mat_dict)\n",
    "\n",
    "fig.savefig(\"Bestfit-dP-\"+experiment+\".png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data-seis_ps[\"dP\"][0][q], cmap=\"seismic\", vmin=-vmax, vmax=vmax)\n",
    "plt.title(\"Misfit dP \"+experiment)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Bestfit_diff-dP-\"+experiment+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.full_like(seis_ps[\"dSg\"][0][0], np.nan)\n",
    "counter = 0\n",
    "for i, m in enumerate(model_shape):\n",
    "    if m:\n",
    "        data[np.unravel_index(i, data.shape)] = preddata[1][counter]\n",
    "        counter += 1\n",
    "\n",
    "vmax = np.nanmax([np.abs(data),np.abs(seis_ps[\"dSw\"][0][q])])\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "\n",
    "im = axes[0].imshow(data, cmap=\"seismic_r\", vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[0].set_title(\"Neural Network dSw \"+experiment)\n",
    "\n",
    "im = axes[1].imshow(seis_ps[\"dSw\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[1].set_title(\"Test Data dSw\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.2, 0.01, 0.6])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "blerg = \"dSw\"\n",
    "mat_dict = {blerg+\"_nn_data\": data, blerg: seis_ps[blerg][0][q]}\n",
    "savemat('matlab/'+blerg+'.mat', mat_dict)\n",
    "\n",
    "fig.savefig(\"Bestfit-dSw-\"+experiment+\".png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data-seis_ps[\"dSw\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax)\n",
    "plt.title(\"Misfit dSw \"+experiment)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Bestfit_diff-dSw-\"+experiment+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.full_like(seis_ps[\"dSg\"][0][0], np.nan)\n",
    "counter = 0\n",
    "for i, m in enumerate(model_shape):\n",
    "    if m:\n",
    "        data[np.unravel_index(i, data.shape)] = preddata[2][counter]\n",
    "        counter += 1\n",
    "\n",
    "vmax = np.nanmax([np.abs(data),np.abs(seis_ps[\"dSg\"][0][q])])\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "\n",
    "im = axes[0].imshow(data, cmap=\"seismic_r\",  vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[0].set_title(\"Neural Network dSg \"+experiment)\n",
    "\n",
    "im = axes[1].imshow(seis_ps[\"dSg\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax, aspect='equal')\n",
    "axes[1].set_title(\"Test Data dSg\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.2, 0.01, 0.6])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "blerg = \"dSg\"\n",
    "mat_dict = {blerg+\"_nn_data\": data, blerg: seis_ps[blerg][0][q]}\n",
    "savemat('matlab/'+blerg+'.mat', mat_dict)\n",
    "\n",
    "fig.savefig(\"Bestfit-dSg-\"+experiment+\".png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(data-seis_ps[\"dSg\"][0][q], cmap=\"seismic_r\", vmin=-vmax, vmax=vmax)\n",
    "plt.title(\"Misfit dSg \"+experiment)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Bestfit_diff-dSg-\"+experiment+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
